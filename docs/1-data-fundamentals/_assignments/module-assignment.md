# Module 1: Data Fundamentals Comprehensive Assignment

This comprehensive assignment combines all key concepts from the Data Fundamentals module. Complete all parts to demonstrate your understanding of data analytics, Python programming, statistics, NumPy operations, and Pandas data analysis.

## Part 1: Introduction to Data Analytics (20 points)

Answer the following questions:

1. What is the primary purpose of data collection?
   - a. To analyze data
   - b. To gather raw material for analysis
   - c. To ensure data accuracy
   - d. To visualize data

2. Which of the following is an example of first-party data?
   - a. Social media insights
   - b. Market research reports
   - c. Customer interactions
   - d. Data aggregators

3. What does GDPR stand for?
   - a. General Data Protection Regulation
   - b. General Data Privacy Regulation
   - c. General Data Protection Regulation
   - d. Global Data Protection Regulation

4. Which method is used for gathering qualitative data?
   - a. Surveys
   - b. Data logging
   - c. Interviews
   - d. Web scraping

5. What is the main focus of predictive analytics?
   - a. Understanding past events
   - b. Analyzing current data
   - c. Forecasting future outcomes
   - d. Summarizing data

6. What does PII stand for?
   - a. Personal Information Identifier
   - b. Protected Information Index
   - c. Personally Identifiable Information
   - d. Private Information Indicator

7. Which of the following is a key principle of data security?
   - a. Data Minimization
   - b. Purpose Limitation
   - c. Confidentiality
   - d. Data Portability

8. What is the purpose of data encryption?
   - a. To analyze data
   - b. To visualize data
   - c. To prevent unauthorized access
   - d. To store data

9. Which lifecycle stage involves removing records with missing data?
   - a. Data Cleaning
   - b. Data Exploration
   - c. Data Collection
   - d. Data Analysis

10. What is the main goal of data cleaning?
    - a. To visualize data
    - b. To collect data
    - c. To remove inaccuracies
    - d. To analyze data

11. What is the role of feature engineering in data science?
    - a. To collect data
    - b. To clean data
    - c. To create new features
    - d. To visualize data

12. Which of the following is a type of secondary data analysis?
    - a. Surveys
    - b. Interviews
    - c. Analyzing existing datasets
    - d. Observations

13. What is the primary focus of the Data Science Lifecycle?
    - a. Data Collection
    - b. Data Cleaning
    - c. Developing and delivering data science projects
    - d. Data Visualization

14. What does the term "data minimization" refer to?
    - a. Collecting as much data as possible
    - b. Storing data indefinitely
    - c. Collecting only necessary data
    - d. Analyzing data

15. Which of the following is a threat to data security?
    - a. Data encryption
    - b. Data backup
    - c. Malware
    - d. Access control

16. What is the purpose of a feedback loop in data analytics?
    - a. To collect data
    - b. To clean data
    - c. To refine the analysis process
    - d. To visualize data

17. Which of the following is an example of third-party data?
    - a. CRM data
    - b. Customer interactions
    - c. Data from data aggregators
    - d. Surveys

18. What is the main benefit of using web scraping?
    - a. To analyze data
    - b. To conduct interviews
    - c. To collect large datasets quickly
    - d. To visualize data

19. What is the significance of the right to erasure under data privacy laws?
    - a. Individuals can access their data
    - b. Individuals can correct their data
    - c. Individuals can request deletion of their data
    - d. Individuals can transfer their data

20. Which of the following best describes the role of data visualization?
    - a. To collect data
    - b. To clean data
    - c. To present data and analysis results
    - d. To analyze data

## Part 2: Python Programming (20 points)

Complete the following programming tasks:

```python
# Task 1: Data Types and Variables
# Create and demonstrate usage of:
# - Integers
# - Floats
# - Strings
# - Boolean
# - Lists
# - Tuples
# - Dictionaries

# Task 2: Functions and Classes
def count_and_return_vowels(text):
    """
    Count and return vowels in the given text
    """
    # Your implementation here

def sum_of_even_numbers(limit):
    """
    Calculate sum of even numbers up to limit
    """
    # Your implementation here

class BankAccount:
    """
    Implement a bank account class with:
    - deposit
    - withdraw
    - get_balance methods
    """
    # Your implementation here

# Test your implementations
```

## Part 3: Statistics (20 points)

Answer these questions and complete the calculations:

1. In a dataset with values [2, 4, 4, 6, 8, 8, 8, 10], what is the mode?
   - a. 4
   - b. 6
   - c. 8
   - d. 10

2. If a dataset has a mean greater than its median, the distribution is likely:
   - a. Symmetrical
   - b. Negatively skewed
   - c. Positively skewed
   - d. Normal

3. The correlation coefficient ranges from:
   - a. -1 to 1
   - b. 0 to 1
   - c. -1 to 0
   - d. -2 to 2

4. Which of the following is not a measure of central tendency?
   - a. Mean
   - b. Median
   - c. Mode
   - d. Range

5. In a normal distribution, approximately what percentage of data falls within one standard deviation of the mean?
   - a. 50%
   - b. 68%
   - c. 95%
   - d. 99%

6. The interquartile range (IQR) is calculated as:
   - a. Q1 - Q3
   - b. Q3 - Q1
   - c. Q2 - Q1
   - d. Q3 - Q2

7. Which probability distribution is used to model the number of successes in a fixed number of trials?
   - a. Normal distribution
   - b. Binomial distribution
   - c. Poisson distribution
   - d. Uniform distribution

8. What does the Central Limit Theorem state about sample means?
   - a. They are always normally distributed
   - b. They approach normal distribution as sample size increases
   - c. They are always equal to the population mean
   - d. They are always skewed

9. In a Poisson distribution, which of the following is true?
   - a. The mean equals the variance
   - b. The mean is greater than the variance
   - c. The mean is less than the variance
   - d. The mean and variance are unrelated

10. The probability density function is used for:
    - a. Discrete distributions only
    - b. Continuous distributions only
    - c. Both discrete and continuous distributions
    - d. Neither discrete nor continuous distributions

11. In a normal distribution, the mean, median, and mode are:
    - a. Always different
    - b. All equal
    - c. Mean equals median only
    - d. Mode equals median only

12. The Z-score represents:
    - a. The probability of an event
    - b. The number of standard deviations from the mean
    - c. The mean of a distribution
    - d. The variance of a distribution

13. Correlation measures:
    - a. The strength and direction of a linear relationship
    - b. Causation between variables
    - c. The slope of a line
    - d. The variance between variables

14. A covariance value of zero indicates:
    - a. Perfect positive correlation
    - b. Perfect negative correlation
    - c. No linear relationship
    - d. Strong relationship

15. In a scatter plot, a positive correlation shows:
    - a. Points moving downward from left to right
    - b. Points moving upward from left to right
    - c. Points in a random pattern
    - d. Points in a circular pattern

16. Which measure of central tendency is most affected by outliers?
    - a. Mean
    - b. Median
    - c. Mode
    - d. Range

17. The Poisson distribution is used to model:
    - a. Number of successes in fixed trials
    - b. Number of events in a fixed interval
    - c. Continuous data only
    - d. Normally distributed data

18. In a negatively skewed distribution:
    - a. The mean is greater than the median
    - b. The mean equals the median
    - c. The mean is less than the median
    - d. The mode is always zero

19. For a binomial distribution with n trials and probability p, the mean is:
    - a. n ร p
    - b. n + p
    - c. n รท p
    - d. n - p

20. The standard deviation is calculated by:
    - a. Subtracting each value from the mean and dividing by n
    - b. Finding the square root of the variance
    - c. Taking the absolute difference between maximum and minimum values
    - d. Multiplying the mean by the sample size

## Part 4: NumPy Operations (20 points)

Using the following setup:

```python
import numpy as np

# Student test scores for 3 subjects (math, science, english)
scores = np.array([
    [85, 92, 78],
    [90, 88, 95],
    [75, 70, 85],
    [88, 95, 92],
    [65, 72, 68],
    [95, 88, 85],
    [78, 85, 82],
    [92, 89, 90]
])

# Student names
names = np.array(['Alice', 'Bob', 'Charlie', 'David', 'Eve', 'Frank', 'Grace', 'Henry'])

# Random 4x4 matrix for linear algebra operations
matrix_A = np.random.randint(1, 10, size=(4, 4))
matrix_B = np.random.randint(1, 10, size=(4, 4))
```

Complete these tasks:

1. Array Operations and Indexing
   - Calculate the average score for each student across all subjects
   - Find the highest score in each subject
   - Select all students who scored above 90 in any subject
   - Create a boolean mask to find students who passed all subjects (passing score is 70)

2. Array Manipulation
   - Reshape the scores array to be 12x2
   - Create a new array with standardized scores
   - Sort the students by their average score in descending order
   - Use array methods to find min, max and mean for each subject

3. Linear Algebra
   - Multiply matrix_A and matrix_B using matrix multiplication
   - Calculate the determinant of matrix_A
   - Find the inverse of matrix_A (if it exists)
   - Calculate the eigenvalues of matrix_A

4. Bonus Challenge
Create a function that takes a student's name as input and returns:
   - Their individual scores
   - Their ranking in each subject
   - A boolean indicating if they're in the top 3 performers overall

## Part 5: Pandas Data Analysis (20 points)

Using this e-commerce dataset:

```python
import pandas as pd
import numpy as np

# Set random seed for reproducibility
np.random.seed(2024)

# Create a mock dataset
data = {
    'order_id': range(1, 11),
    'customer_id': np.random.randint(1000, 1020, size=10),
    'product_id': np.random.randint(100, 110, size=10),
    'quantity': np.random.randint(1, 5, size=10),
    'price': np.random.uniform(10.0, 100.0, size=10),
    'order_date': pd.date_range(start='2021-01-01', periods=10, freq='D')
}

df = pd.DataFrame(data)
```

Complete these tasks:

1. Basic Data Exploration
   - Display the data types of each column
   - Calculate basic statistics for the 'quantity' column
   - Check for missing values

2. Data Manipulation & Arithmetic
   - Create a new column 'total_amount' by multiplying 'quantity' and 'price'
   - Calculate daily revenue
   - Add 5% tax to all prices
   - Find orders where quantity is above mean

3. Sorting & Ranking
   - Sort by total_amount in descending order
   - Rank orders based on price
   - Find top 3 orders by total_amount
   - Sort by date and quantity

4. Function Application
   - Create and apply an order categorization function
   - Format currency columns
   - Calculate cumulative sums

5. Index Operations
   - Set order_date as index
   - Select first 5 days of orders
   - Reset index
   - Create copy with order_id as index

## Submission Guidelines

1. Submit your solution as a Jupyter notebook containing:
   - Well-documented code for each part
   - Clear explanations of your approach
   - Visualizations where appropriate
   - Insights and conclusions from your analysis

2. Code Quality Requirements:
   - Follow PEP 8 style guidelines
   - Include appropriate error handling
   - Write clear, descriptive comments
   - Use efficient, vectorized operations where possible

3. Analysis Requirements:
   - Support conclusions with data
   - Include visualizations
   - Provide business context for findings
   - Suggest potential actions based on insights

## Grading Criteria

- Part 1: Data Analytics Quiz (20%)
- Part 2: Python Programming (20%)
- Part 3: Statistics Quiz (20%)
- Part 4: NumPy Operations (20%)
- Part 5: Pandas Analysis (20%)

Each part will be evaluated on:
- Correctness of implementation
- Code quality and efficiency
- Documentation and presentation
- Analysis depth and insights
