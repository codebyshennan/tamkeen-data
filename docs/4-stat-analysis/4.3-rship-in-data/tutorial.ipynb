{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3 Relationships in Data Tutorial\n",
    "\n",
    "This notebook covers key concepts in analyzing relationships in data including:\n",
    "- Understanding Relationships\n",
    "- Correlation Analysis\n",
    "- Simple Linear Regression\n",
    "- Multiple Linear Regression\n",
    "- Model Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Understanding Relationships\n",
    "\n",
    "Let's create some example data to demonstrate different types of relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate different types of relationships\n",
    "x = np.linspace(0, 10, 100)\n",
    "\n",
    "# Linear relationship\n",
    "y_linear = 2 * x + 1 + np.random.normal(0, 1, 100)\n",
    "\n",
    "# Quadratic relationship\n",
    "y_quadratic = x**2 + np.random.normal(0, 5, 100)\n",
    "\n",
    "# No relationship (random)\n",
    "y_random = np.random.normal(5, 2, 100)\n",
    "\n",
    "# Visualize relationships\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "ax1.scatter(x, y_linear)\n",
    "ax1.set_title('Linear Relationship')\n",
    "\n",
    "ax2.scatter(x, y_quadratic)\n",
    "ax2.set_title('Quadratic Relationship')\n",
    "\n",
    "ax3.scatter(x, y_random)\n",
    "ax3.set_title('No Relationship')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Correlation Analysis\n",
    "\n",
    "Let's explore different correlation measures and their interpretations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate correlations\n",
    "def print_correlations(x, y, relationship_type):\n",
    "    pearson = stats.pearsonr(x, y)\n",
    "    spearman = stats.spearmanr(x, y)\n",
    "    kendall = stats.kendalltau(x, y)\n",
    "    \n",
    "    print(f\"\\nCorrelations for {relationship_type} relationship:\")\n",
    "    print(f\"Pearson's r: {pearson[0]:.4f} (p-value: {pearson[1]:.4f})\")\n",
    "    print(f\"Spearman's rho: {spearman[0]:.4f} (p-value: {spearman[1]:.4f})\")\n",
    "    print(f\"Kendall's tau: {kendall[0]:.4f} (p-value: {kendall[1]:.4f})\")\n",
    "\n",
    "print_correlations(x, y_linear, 'Linear')\n",
    "print_correlations(x, y_quadratic, 'Quadratic')\n",
    "print_correlations(x, y_random, 'Random')\n",
    "\n",
    "# Create correlation matrix visualization\n",
    "data = pd.DataFrame({\n",
    "    'X': x,\n",
    "    'Linear': y_linear,\n",
    "    'Quadratic': y_quadratic,\n",
    "    'Random': y_random\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simple Linear Regression\n",
    "\n",
    "Let's implement and analyze a simple linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare data for simple linear regression\n",
    "X = x.reshape(-1, 1)\n",
    "y = y_linear\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Fit linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print model results\n",
    "print(f\"Coefficient (slope): {model.coef_[0]:.4f}\")\n",
    "print(f\"Intercept: {model.intercept_:.4f}\")\n",
    "print(f\"R-squared: {r2_score(y_test, y_pred):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")\n",
    "\n",
    "# Visualize the regression line\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_test, y_test, color='blue', label='Actual')\n",
    "plt.plot(X_test, y_pred, color='red', label='Predicted')\n",
    "plt.title('Simple Linear Regression')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Multiple Linear Regression\n",
    "\n",
    "Let's explore multiple linear regression with multiple predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Generate data for multiple regression\n",
    "n_samples = 100\n",
    "X_multi = np.random.normal(size=(n_samples, 3))  # 3 features\n",
    "y_multi = 2 * X_multi[:, 0] + 0.5 * X_multi[:, 1] - 1 * X_multi[:, 2] + np.random.normal(0, 0.5, n_samples)\n",
    "\n",
    "# Split data\n",
    "X_train_multi, X_test_multi, y_train_multi, y_test_multi = train_test_split(\n",
    "    X_multi, y_multi, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Fit multiple regression model\n",
    "model_multi = LinearRegression()\n",
    "model_multi.fit(X_train_multi, y_train_multi)\n",
    "\n",
    "# Print coefficients and performance metrics\n",
    "print(\"Coefficients:\")\n",
    "for i, coef in enumerate(model_multi.coef_):\n",
    "    print(f\"Feature {i+1}: {coef:.4f}\")\n",
    "print(f\"\\nIntercept: {model_multi.intercept_:.4f}\")\n",
    "\n",
    "# Make predictions and evaluate\n",
    "y_pred_multi = model_multi.predict(X_test_multi)\n",
    "print(f\"\\nR-squared: {r2_score(y_test_multi, y_pred_multi):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test_multi, y_pred_multi)):.4f}\")\n",
    "\n",
    "# Visualize actual vs predicted values\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(y_test_multi, y_pred_multi)\n",
    "plt.plot([y_test_multi.min(), y_test_multi.max()], [y_test_multi.min(), y_test_multi.max()], 'r--')\n",
    "plt.xlabel('Actual Values')\n",
    "plt.ylabel('Predicted Values')\n",
    "plt.title('Actual vs Predicted Values')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Diagnostics\n",
    "\n",
    "Let's perform diagnostic tests to validate our regression assumptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Calculate residuals\n",
    "residuals = y_test_multi - y_pred_multi\n",
    "\n",
    "# Create diagnostic plots\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Residuals vs Fitted\n",
    "ax1.scatter(y_pred_multi, residuals)\n",
    "ax1.axhline(y=0, color='r', linestyle='--')\n",
    "ax1.set_xlabel('Fitted Values')\n",
    "ax1.set_ylabel('Residuals')\n",
    "ax1.set_title('Residuals vs Fitted')\n",
    "\n",
    "# Q-Q plot\n",
    "stats.probplot(residuals, dist=\"norm\", plot=ax2)\n",
    "ax2.set_title('Normal Q-Q Plot')\n",
    "\n",
    "# Scale-Location\n",
    "ax3.scatter(y_pred_multi, np.sqrt(np.abs(residuals)))\n",
    "ax3.set_xlabel('Fitted Values')\n",
    "ax3.set_ylabel('âˆš|Residuals|')\n",
    "ax3.set_title('Scale-Location')\n",
    "\n",
    "# Residuals histogram\n",
    "ax4.hist(residuals, bins=20)\n",
    "ax4.set_xlabel('Residuals')\n",
    "ax4.set_ylabel('Frequency')\n",
    "ax4.set_title('Residuals Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Perform statistical tests\n",
    "print(\"Shapiro-Wilk test for normality of residuals:\")\n",
    "print(stats.shapiro(residuals))\n",
    "\n",
    "print(\"\\nBreusch-Pagan test for homoscedasticity:\")\n",
    "print(stats.breutsch_pagan(X_test_multi, residuals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Exercises\n",
    "\n",
    "1. Create a dataset with non-linear relationships and explore transformation techniques.\n",
    "\n",
    "2. Implement polynomial regression and compare it with simple linear regression.\n",
    "\n",
    "3. Analyze multicollinearity in a multiple regression model using VIF.\n",
    "\n",
    "4. Perform cross-validation to assess model stability.\n",
    "\n",
    "5. Handle outliers and influential points in regression analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
