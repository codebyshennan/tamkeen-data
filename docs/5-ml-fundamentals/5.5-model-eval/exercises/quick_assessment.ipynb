{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick Assessment: Find Your Starting Level\n",
    "\n",
    "## üéØ Purpose\n",
    "\n",
    "This quick assessment helps you determine which level of exercises to start with. It should take about **5-10 minutes** to complete.\n",
    "\n",
    "## üìã Instructions\n",
    "\n",
    "1. **Answer honestly** - this is for your benefit!\n",
    "2. **Don't look up answers** - use your current knowledge\n",
    "3. **It's okay to not know** - that's why you're here to learn!\n",
    "4. **Count your correct answers** at the end\n",
    "\n",
    "## üèÅ Scoring Guide\n",
    "\n",
    "- **0-3 correct**: Start with **Level 1** (Beginner)\n",
    "- **4-6 correct**: Start with **Level 2** (Intermediate) \n",
    "- **7-9 correct**: Start with **Level 3** (Advanced)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Cross-Validation Basics\n",
    "\n",
    "**Scenario**: You have a dataset with 1000 samples and want to use 5-fold cross-validation.\n",
    "\n",
    "**Question**: How many samples will be in each training set?\n",
    "\n",
    "A) 200 samples  \n",
    "B) 800 samples  \n",
    "C) 1000 samples  \n",
    "D) 500 samples  \n",
    "\n",
    "**Your Answer**: ___\n",
    "\n",
    "<details>\n",
    "<summary>Click for Answer & Explanation</summary>\n",
    "\n",
    "**Correct Answer: B) 800 samples**\n",
    "\n",
    "**Explanation**: In 5-fold CV, data is split into 5 equal parts (200 samples each). For each fold, 4 parts are used for training (4 √ó 200 = 800) and 1 part for testing (200).\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Confusion Matrix Interpretation\n",
    "\n",
    "**Given this confusion matrix for a binary classifier**:\n",
    "\n",
    "```\n",
    "           Predicted\n",
    "         0    1\n",
    "Actual 0 85   15\n",
    "       1 10   90\n",
    "```\n",
    "\n",
    "**Question**: What is the precision for class 1?\n",
    "\n",
    "A) 90/100 = 0.90  \n",
    "B) 90/105 = 0.86  \n",
    "C) 85/95 = 0.89  \n",
    "D) 90/200 = 0.45  \n",
    "\n",
    "**Your Answer**: ___\n",
    "\n",
    "<details>\n",
    "<summary>Click for Answer & Explanation</summary>\n",
    "\n",
    "**Correct Answer: B) 90/105 = 0.86**\n",
    "\n",
    "**Explanation**: Precision = True Positives / (True Positives + False Positives) = 90 / (90 + 15) = 90/105 = 0.86\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Hyperparameter Tuning\n",
    "\n",
    "**Question**: Which statement about Grid Search vs Random Search is TRUE?\n",
    "\n",
    "A) Grid Search is always faster than Random Search  \n",
    "B) Random Search explores all possible combinations  \n",
    "C) Random Search can be more efficient when many parameters don't affect performance  \n",
    "D) Grid Search is better for continuous parameters  \n",
    "\n",
    "**Your Answer**: ___\n",
    "\n",
    "<details>\n",
    "<summary>Click for Answer & Explanation</summary>\n",
    "\n",
    "**Correct Answer: C) Random Search can be more efficient when many parameters don't affect performance**\n",
    "\n",
    "**Explanation**: Random Search can find good solutions faster when only a few parameters significantly impact performance, as it doesn't waste time on systematic but irrelevant combinations.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: Metric Selection\n",
    "\n",
    "**Scenario**: You're building a model to detect rare diseases (1% of population has the disease).\n",
    "\n",
    "**Question**: Which metric would be MOST appropriate as your primary evaluation metric?\n",
    "\n",
    "A) Accuracy  \n",
    "B) Precision  \n",
    "C) Recall  \n",
    "D) F1-Score  \n",
    "\n",
    "**Your Answer**: ___\n",
    "\n",
    "<details>\n",
    "<summary>Click for Answer & Explanation</summary>\n",
    "\n",
    "**Correct Answer: C) Recall**\n",
    "\n",
    "**Explanation**: For rare disease detection, missing a positive case (false negative) is much worse than a false alarm. High recall ensures we catch most disease cases, even if we have some false positives.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: Data Leakage\n",
    "\n",
    "**Question**: Which of these would cause data leakage in cross-validation?\n",
    "\n",
    "A) Using different random seeds for each fold  \n",
    "B) Scaling features before splitting the data  \n",
    "C) Using stratified sampling  \n",
    "D) Setting random_state parameter  \n",
    "\n",
    "**Your Answer**: ___\n",
    "\n",
    "<details>\n",
    "<summary>Click for Answer & Explanation</summary>\n",
    "\n",
    "**Correct Answer: B) Scaling features before splitting the data**\n",
    "\n",
    "**Explanation**: Scaling before splitting means the test set statistics influence the training set preprocessing, causing data leakage. Scaling should be done within each CV fold.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: ROC Curve Understanding\n",
    "\n",
    "**Question**: What does the Area Under the ROC Curve (AUC) represent?\n",
    "\n",
    "A) The probability that the model ranks a random positive example higher than a random negative example  \n",
    "B) The accuracy of the model at the optimal threshold  \n",
    "C) The precision of the model across all thresholds  \n",
    "D) The recall of the model at 50% threshold  \n",
    "\n",
    "**Your Answer**: ___\n",
    "\n",
    "<details>\n",
    "<summary>Click for Answer & Explanation</summary>\n",
    "\n",
    "**Correct Answer: A) The probability that the model ranks a random positive example higher than a random negative example**\n",
    "\n",
    "**Explanation**: AUC-ROC measures the model's ability to distinguish between classes. It represents the probability that a randomly chosen positive instance will be ranked higher than a randomly chosen negative instance.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7: Nested Cross-Validation\n",
    "\n",
    "**Question**: Why would you use nested cross-validation?\n",
    "\n",
    "A) To speed up hyperparameter tuning  \n",
    "B) To get an unbiased estimate of model performance when doing hyperparameter tuning  \n",
    "C) To reduce overfitting to the training set  \n",
    "D) To handle imbalanced datasets better  \n",
    "\n",
    "**Your Answer**: ___\n",
    "\n",
    "<details>\n",
    "<summary>Click for Answer & Explanation</summary>\n",
    "\n",
    "**Correct Answer: B) To get an unbiased estimate of model performance when doing hyperparameter tuning**\n",
    "\n",
    "**Explanation**: Nested CV separates hyperparameter optimization from performance estimation, preventing optimistic bias that occurs when the same data is used for both tuning and evaluation.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8: Learning Curves\n",
    "\n",
    "**Question**: If training score is high but validation score is low and flat, this indicates:\n",
    "\n",
    "A) Underfitting - need more complex model  \n",
    "B) Overfitting - need more data or regularization  \n",
    "C) Good fit - model is optimal  \n",
    "D) Data quality issues  \n",
    "\n",
    "**Your Answer**: ___\n",
    "\n",
    "<details>\n",
    "<summary>Click for Answer & Explanation</summary>\n",
    "\n",
    "**Correct Answer: B) Overfitting - need more data or regularization**\n",
    "\n",
    "**Explanation**: High training score with low, flat validation score indicates the model memorizes training data but doesn't generalize. This is classic overfitting.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9: Production Considerations\n",
    "\n",
    "**Question**: In production, which is MOST important for monitoring model performance?\n",
    "\n",
    "A) Training accuracy  \n",
    "B) Cross-validation scores  \n",
    "C) Distribution drift in input features  \n",
    "D) Model complexity  \n",
    "\n",
    "**Your Answer**: ___\n",
    "\n",
    "<details>\n",
    "<summary>Click for Answer & Explanation</summary>\n",
    "\n",
    "**Correct Answer: C) Distribution drift in input features**\n",
    "\n",
    "**Explanation**: In production, data distribution changes over time. Monitoring feature drift helps detect when model performance may degrade due to changing data patterns.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìä Calculate Your Score\n",
    "\n",
    "Count how many questions you answered correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enter your answers here (use the letter: A, B, C, or D)\n",
    "your_answers = {\n",
    "    'Q1': '',  # Your answer for Question 1\n",
    "    'Q2': '',  # Your answer for Question 2\n",
    "    'Q3': '',  # Your answer for Question 3\n",
    "    'Q4': '',  # Your answer for Question 4\n",
    "    'Q5': '',  # Your answer for Question 5\n",
    "    'Q6': '',  # Your answer for Question 6\n",
    "    'Q7': '',  # Your answer for Question 7\n",
    "    'Q8': '',  # Your answer for Question 8\n",
    "    'Q9': '',  # Your answer for Question 9\n",
    "}\n",
    "\n",
    "# Correct answers\n",
    "correct_answers = {\n",
    "    'Q1': 'B',\n",
    "    'Q2': 'B', \n",
    "    'Q3': 'C',\n",
    "    'Q4': 'C',\n",
    "    'Q5': 'B',\n",
    "    'Q6': 'A',\n",
    "    'Q7': 'B',\n",
    "    'Q8': 'B',\n",
    "    'Q9': 'C'\n",
    "}\n",
    "\n",
    "# Calculate score\n",
    "score = 0\n",
    "for q in correct_answers:\n",
    "    if your_answers[q].upper() == correct_answers[q]:\n",
    "        score += 1\n",
    "        print(f\"‚úÖ {q}: Correct!\")\n",
    "    else:\n",
    "        print(f\"‚ùå {q}: Your answer: {your_answers[q]}, Correct: {correct_answers[q]}\")\n",
    "\n",
    "print(f\"\\nüéØ Your Score: {score}/9 ({score/9*100:.1f}%)\")\n",
    "\n",
    "# Recommendation\n",
    "if score <= 3:\n",
    "    level = \"Level 1 (Beginner)\"\n",
    "    recommendation = \"Start with the fundamentals! Level 1 will build your foundation.\"\n",
    "elif score <= 6:\n",
    "    level = \"Level 2 (Intermediate)\"\n",
    "    recommendation = \"You have good basics! Level 2 will help you integrate concepts.\"\n",
    "else:\n",
    "    level = \"Level 3 (Advanced)\"\n",
    "    recommendation = \"Strong foundation! Jump to Level 3 for real-world challenges.\"\n",
    "\n",
    "print(f\"\\nüöÄ Recommended Starting Level: {level}\")\n",
    "print(f\"üí° {recommendation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Your Learning Path\n",
    "\n",
    "Based on your score, here's your recommended path:\n",
    "\n",
    "### If you scored 0-3 (Level 1 - Beginner)\n",
    "**Perfect!** You're exactly where you should be. Start with:\n",
    "1. [Basic Cross-Validation](./level1_basic_cross_validation.ipynb)\n",
    "2. [Understanding Metrics](./level1_understanding_metrics.ipynb)\n",
    "3. [Simple Hyperparameter Tuning](./level1_simple_hyperparameter_tuning.ipynb)\n",
    "\n",
    "**Focus**: Take your time with each concept. Understanding is more important than speed.\n",
    "\n",
    "### If you scored 4-6 (Level 2 - Intermediate)\n",
    "**Great foundation!** You can start with intermediate exercises:\n",
    "1. [Complete Model Evaluation Pipeline](./level2_complete_evaluation_pipeline.ipynb)\n",
    "2. [Advanced Hyperparameter Optimization](./level2_advanced_hyperparameter_optimization.ipynb)\n",
    "3. [Model Selection and Validation](./level2_model_selection_validation.ipynb)\n",
    "\n",
    "**Tip**: If any Level 2 exercise feels too challenging, don't hesitate to review Level 1 materials.\n",
    "\n",
    "### If you scored 7-9 (Level 3 - Advanced)\n",
    "**Excellent knowledge!** Jump into real-world scenarios:\n",
    "1. [Healthcare Diagnostic Model](./level3_healthcare_diagnostic.ipynb)\n",
    "2. [Financial Risk Assessment](./level3_financial_risk_assessment.ipynb)\n",
    "3. [Production Model Monitoring](./level3_production_monitoring.ipynb)\n",
    "\n",
    "**Challenge**: Try to complete exercises without looking at hints first.\n",
    "\n",
    "## üìö Additional Resources\n",
    "\n",
    "Regardless of your level, these resources will help:\n",
    "\n",
    "- **[Main Tutorial](../tutorial.ipynb)**: Comprehensive walkthrough\n",
    "- **[Cross-Validation Guide](../cross-validation.md)**: Deep dive into CV techniques\n",
    "- **[Hyperparameter Tuning Guide](../hyperparameter-tuning.md)**: Advanced optimization strategies\n",
    "- **[Metrics Guide](../metrics.md)**: Complete metrics reference\n",
    "\n",
    "## üéâ Ready to Start?\n",
    "\n",
    "Click on your recommended exercise above to begin your learning journey!\n",
    "\n",
    "Remember: **Learning is a journey, not a race.** Take your time, ask questions, and enjoy the process! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
