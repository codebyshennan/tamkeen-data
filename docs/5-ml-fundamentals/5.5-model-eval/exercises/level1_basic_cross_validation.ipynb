{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level 1: Basic Cross-Validation\n",
    "\n",
    "## üéØ Learning Objectives\n",
    "\n",
    "By the end of this exercise, you will be able to:\n",
    "1. **Understand** why we need cross-validation\n",
    "2. **Implement** basic k-fold cross-validation\n",
    "3. **Interpret** cross-validation results\n",
    "4. **Compare** different cross-validation strategies\n",
    "\n",
    "## ‚è±Ô∏è Time Estimate\n",
    "**30-45 minutes** (take your time to understand each concept)\n",
    "\n",
    "## üìö Prerequisites\n",
    "- Basic Python programming\n",
    "- Understanding of train/test splits\n",
    "- Familiarity with scikit-learn basics\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§î Why Do We Need Cross-Validation?\n",
    "\n",
    "### The Problem with Single Train/Test Split\n",
    "\n",
    "**Real-world analogy**: Imagine judging a student's performance based on just one exam. What if:\n",
    "- The student had a bad day?\n",
    "- The exam was unusually easy or hard?\n",
    "- The topics didn't represent the full curriculum?\n",
    "\n",
    "**Same problem with ML models**: A single train/test split might:\n",
    "- Give overly optimistic or pessimistic results\n",
    "- Not represent the true model performance\n",
    "- Be influenced by random chance in data splitting\n",
    "\n",
    "### The Cross-Validation Solution\n",
    "\n",
    "**Cross-validation** is like giving multiple exams and averaging the scores:\n",
    "- More reliable performance estimate\n",
    "- Reduces impact of random variation\n",
    "- Better understanding of model stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Setup: Import Libraries and Create Data\n",
    "\n",
    "**What we're doing**: Setting up our environment and creating a practice dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning tools\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, KFold, StratifiedKFold\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set random seed for reproducible results\n",
    "np.random.seed(42)\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üéØ Ready to learn cross-validation!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Practice Dataset\n",
    "\n",
    "**What we're doing**: Creating a synthetic classification dataset to practice with.\n",
    "\n",
    "**Why synthetic data**: \n",
    "- We know the \"ground truth\"\n",
    "- Controlled complexity\n",
    "- Focus on learning concepts, not data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic classification dataset\n",
    "print(\"üîß Creating practice dataset...\")\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,        # 1000 data points\n",
    "    n_features=10,         # 10 input features\n",
    "    n_informative=8,       # 8 features are actually useful\n",
    "    n_redundant=2,         # 2 features are combinations of others\n",
    "    n_clusters_per_class=1, # Simple structure\n",
    "    random_state=42        # For reproducible results\n",
    ")\n",
    "\n",
    "print(f\"üìä Dataset created:\")\n",
    "print(f\"   ‚Ä¢ {X.shape[0]} samples (data points)\")\n",
    "print(f\"   ‚Ä¢ {X.shape[1]} features (input variables)\")\n",
    "print(f\"   ‚Ä¢ Target distribution: {np.bincount(y)}\")\n",
    "print(f\"     - Class 0: {np.bincount(y)[0]} samples\")\n",
    "print(f\"     - Class 1: {np.bincount(y)[1]} samples\")\n",
    "\n",
    "# Scale the features (important for many algorithms)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "print(\"\\n‚öñÔ∏è Features scaled to have mean=0 and std=1\")\n",
    "print(f\"   ‚Ä¢ Mean: {X_scaled.mean():.3f}\")\n",
    "print(f\"   ‚Ä¢ Standard deviation: {X_scaled.std():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìñ Part 1: Understanding the Problem with Single Split\n",
    "\n",
    "**What we're doing**: Demonstrating why a single train/test split can be unreliable.\n",
    "\n",
    "**The experiment**: \n",
    "1. Perform multiple random train/test splits\n",
    "2. Train the same model on each split\n",
    "3. See how much the results vary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ Experiment: Multiple Random Train/Test Splits\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# We'll try 10 different random splits\n",
    "n_splits = 10\n",
    "scores = []\n",
    "\n",
    "# Create our model (Logistic Regression)\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "print(\"Performing 10 different train/test splits...\\n\")\n",
    "\n",
    "for i in range(n_splits):\n",
    "    # Different random_state for each split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=i\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "    \n",
    "    print(f\"Split {i+1:2d}: Accuracy = {score:.4f}\")\n",
    "\n",
    "# Analyze the results\n",
    "scores = np.array(scores)\n",
    "print(\"\\nüìä Results Summary:\")\n",
    "print(f\"   ‚Ä¢ Mean accuracy: {scores.mean():.4f}\")\n",
    "print(f\"   ‚Ä¢ Standard deviation: {scores.std():.4f}\")\n",
    "print(f\"   ‚Ä¢ Range: {scores.min():.4f} to {scores.max():.4f}\")\n",
    "print(f\"   ‚Ä¢ Difference: {scores.max() - scores.min():.4f}\")\n",
    "\n",
    "# Visualize the variation\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, n_splits + 1), scores, 'bo-', linewidth=2, markersize=8)\n",
    "plt.axhline(y=scores.mean(), color='red', linestyle='--', \n",
    "            label=f'Mean: {scores.mean():.4f}')\n",
    "plt.fill_between(range(1, n_splits + 1), \n",
    "                 scores.mean() - scores.std(), \n",
    "                 scores.mean() + scores.std(), \n",
    "                 alpha=0.2, color='red', \n",
    "                 label=f'¬±1 std: {scores.std():.4f}')\n",
    "\n",
    "plt.xlabel('Split Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy Variation Across Different Train/Test Splits')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nü§î What this shows:\")\n",
    "if scores.std() > 0.02:\n",
    "    print(\"   ‚ö†Ô∏è High variation! Single split results are unreliable.\")\n",
    "else:\n",
    "    print(\"   ‚úÖ Low variation, but cross-validation is still better practice.\")\n",
    "    \n",
    "print(\"   üí° This is why we need cross-validation for reliable estimates!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Checkpoint Question 1\n",
    "\n",
    "**Think about it**: Why do you think the accuracy scores vary across different train/test splits?\n",
    "\n",
    "<details>\n",
    "<summary>Click for explanation</summary>\n",
    "\n",
    "**Answer**: The variation occurs because:\n",
    "1. **Random sampling**: Different splits include different subsets of data\n",
    "2. **Data distribution**: Some splits might have easier/harder test samples\n",
    "3. **Class balance**: Random splits might not preserve class proportions perfectly\n",
    "4. **Sample size**: With limited data, small changes in samples can affect results\n",
    "\n",
    "This variation is exactly why cross-validation gives us more reliable estimates!\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìñ Part 2: Basic K-Fold Cross-Validation\n",
    "\n",
    "**What is K-Fold Cross-Validation?**\n",
    "\n",
    "**The process**:\n",
    "1. **Split** data into K equal parts (\"folds\")\n",
    "2. **For each fold**:\n",
    "   - Use that fold as test set\n",
    "   - Use remaining K-1 folds as training set\n",
    "   - Train model and evaluate\n",
    "3. **Average** the K results\n",
    "\n",
    "**Visual representation** (5-fold example):\n",
    "```\n",
    "Fold 1: [TEST] [TRAIN] [TRAIN] [TRAIN] [TRAIN]\n",
    "Fold 2: [TRAIN] [TEST] [TRAIN] [TRAIN] [TRAIN]\n",
    "Fold 3: [TRAIN] [TRAIN] [TEST] [TRAIN] [TRAIN]\n",
    "Fold 4: [TRAIN] [TRAIN] [TRAIN] [TEST] [TRAIN]\n",
    "Fold 5: [TRAIN] [TRAIN] [TRAIN] [TRAIN] [TEST]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Implementation (Understanding the Process)\n",
    "\n",
    "**What we're doing**: Implementing k-fold CV step-by-step to understand the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîß Manual 5-Fold Cross-Validation Implementation\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Set up 5-fold cross-validation\n",
    "k_folds = 5\n",
    "kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "\n",
    "# Store results for each fold\n",
    "fold_scores = []\n",
    "fold_details = []\n",
    "\n",
    "print(f\"Splitting {len(X_scaled)} samples into {k_folds} folds...\\n\")\n",
    "\n",
    "# Perform cross-validation manually\n",
    "for fold_num, (train_idx, test_idx) in enumerate(kf.split(X_scaled), 1):\n",
    "    print(f\"üìÅ Fold {fold_num}:\")\n",
    "    \n",
    "    # Split data for this fold\n",
    "    X_train_fold = X_scaled[train_idx]\n",
    "    X_test_fold = X_scaled[test_idx]\n",
    "    y_train_fold = y[train_idx]\n",
    "    y_test_fold = y[test_idx]\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Training samples: {len(X_train_fold)}\")\n",
    "    print(f\"   ‚Ä¢ Test samples: {len(X_test_fold)}\")\n",
    "    \n",
    "    # Train model\n",
    "    model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    model.fit(X_train_fold, y_train_fold)\n",
    "    \n",
    "    # Evaluate\n",
    "    score = model.score(X_test_fold, y_test_fold)\n",
    "    fold_scores.append(score)\n",
    "    \n",
    "    # Store details\n",
    "    fold_details.append({\n",
    "        'fold': fold_num,\n",
    "        'train_size': len(X_train_fold),\n",
    "        'test_size': len(X_test_fold),\n",
    "        'accuracy': score\n",
    "    })\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Accuracy: {score:.4f}\")\n",
    "    print()\n",
    "\n",
    "# Calculate final results\n",
    "cv_mean = np.mean(fold_scores)\n",
    "cv_std = np.std(fold_scores)\n",
    "\n",
    "print(\"üìä Cross-Validation Results:\")\n",
    "print(f\"   ‚Ä¢ Individual fold scores: {[f'{score:.4f}' for score in fold_scores]}\")\n",
    "print(f\"   ‚Ä¢ Mean CV score: {cv_mean:.4f}\")\n",
    "print(f\"   ‚Ä¢ Standard deviation: {cv_std:.4f}\")\n",
    "print(f\"   ‚Ä¢ 95% Confidence interval: {cv_mean:.4f} ¬± {cv_std * 2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Scikit-Learn's Built-in Function\n",
    "\n",
    "**What we're doing**: Using scikit-learn's `cross_val_score` function for the same task.\n",
    "\n",
    "**Why this is better**: \n",
    "- Less code\n",
    "- Less error-prone\n",
    "- Optimized implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Using Scikit-Learn's cross_val_score\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create model\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores_sklearn = cross_val_score(\n",
    "    model, X_scaled, y, cv=5, scoring='accuracy'\n",
    ")\n",
    "\n",
    "print(f\"Cross-validation scores: {[f'{score:.4f}' for score in cv_scores_sklearn]}\")\n",
    "print(f\"Mean: {cv_scores_sklearn.mean():.4f}\")\n",
    "print(f\"Std:  {cv_scores_sklearn.std():.4f}\")\n",
    "\n",
    "# Compare with our manual implementation\n",
    "print(\"\\nüîç Comparison with Manual Implementation:\")\n",
    "print(f\"Manual mean:    {cv_mean:.4f}\")\n",
    "print(f\"Sklearn mean:   {cv_scores_sklearn.mean():.4f}\")\n",
    "print(f\"Difference:     {abs(cv_mean - cv_scores_sklearn.mean()):.6f}\")\n",
    "\n",
    "if abs(cv_mean - cv_scores_sklearn.mean()) < 0.001:\n",
    "    print(\"‚úÖ Results match! Our manual implementation is correct.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Small differences due to different random splits.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Checkpoint Question 2\n",
    "\n",
    "**Your turn!** Complete the code below to perform 10-fold cross-validation:\n",
    "\n",
    "```python\n",
    "# TODO: Perform 10-fold cross-validation\n",
    "cv_scores_10fold = cross_val_score(\n",
    "    model, X_scaled, y, cv=___, scoring='accuracy'  # Fill in the blank\n",
    ")\n",
    "\n",
    "print(f\"10-fold CV mean: {cv_scores_10fold.mean():.4f}\")\n",
    "print(f\"10-fold CV std:  {cv_scores_10fold.std():.4f}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Complete this code\n",
    "cv_scores_10fold = cross_val_score(\n",
    "    model, X_scaled, y, cv=___, scoring='accuracy'  # Replace ___ with the correct value\n",
    ")\n",
    "\n",
    "print(f\"10-fold CV mean: {cv_scores_10fold.mean():.4f}\")\n",
    "print(f\"10-fold CV std:  {cv_scores_10fold.std():.4f}\")\n",
    "\n",
    "# Compare with 5-fold\n",
    "print(f\"\\nüìä Comparison:\")\n",
    "print(f\"5-fold:  {cv_scores_sklearn.mean():.4f} ¬± {cv_scores_sklearn.std():.4f}\")\n",
    "print(f\"10-fold: {cv_scores_10fold.mean():.4f} ¬± {cv_scores_10fold.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click for solution</summary>\n",
    "\n",
    "```python\n",
    "cv_scores_10fold = cross_val_score(\n",
    "    model, X_scaled, y, cv=10, scoring='accuracy'\n",
    ")\n",
    "```\n",
    "\n",
    "**Explanation**: The `cv` parameter specifies the number of folds. For 10-fold cross-validation, we use `cv=10`.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìñ Part 3: Stratified Cross-Validation\n",
    "\n",
    "**What is Stratified Cross-Validation?**\n",
    "\n",
    "**The problem**: Regular k-fold might create imbalanced folds by chance.\n",
    "\n",
    "**The solution**: Stratified k-fold ensures each fold has the same class distribution as the original dataset.\n",
    "\n",
    "**When to use**: \n",
    "- **Always** for classification problems\n",
    "- Especially important with imbalanced datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing Regular vs Stratified K-Fold\n",
    "\n",
    "**What we're doing**: Creating an imbalanced dataset and comparing the two approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ Experiment: Regular vs Stratified K-Fold\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Create an imbalanced dataset\n",
    "X_imb, y_imb = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=8,\n",
    "    weights=[0.8, 0.2],  # 80% class 0, 20% class 1\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_imb_scaled = StandardScaler().fit_transform(X_imb)\n",
    "\n",
    "print(f\"üìä Imbalanced dataset created:\")\n",
    "print(f\"   ‚Ä¢ Total samples: {len(y_imb)}\")\n",
    "print(f\"   ‚Ä¢ Class 0: {np.sum(y_imb == 0)} ({np.sum(y_imb == 0)/len(y_imb)*100:.1f}%)\")\n",
    "print(f\"   ‚Ä¢ Class 1: {np.sum(y_imb == 1)} ({np.sum(y_imb == 1)/len(y_imb)*100:.1f}%)\")\n",
    "\n",
    "# Function to check class distribution in folds\n",
    "def analyze_fold_distribution(cv_method, X, y, method_name):\n",
    "    print(f\"\\nüìÅ {method_name} - Fold Analysis:\")\n",
    "    \n",
    "    fold_distributions = []\n",
    "    for fold_num, (train_idx, test_idx) in enumerate(cv_method.split(X, y), 1):\n",
    "        test_y = y[test_idx]\n",
    "        class_0_pct = np.sum(test_y == 0) / len(test_y) * 100\n",
    "        class_1_pct = np.sum(test_y == 1) / len(test_y) * 100\n",
    "        \n",
    "        fold_distributions.append((class_0_pct, class_1_pct))\n",
    "        print(f\"   Fold {fold_num}: Class 0: {class_0_pct:.1f}%, Class 1: {class_1_pct:.1f}%\")\n",
    "    \n",
    "    return fold_distributions\n",
    "\n",
    "# Regular K-Fold\n",
    "regular_kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "regular_dist = analyze_fold_distribution(regular_kf, X_imb_scaled, y_imb, \"Regular K-Fold\")\n",
    "\n",
    "# Stratified K-Fold\n",
    "stratified_kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "stratified_dist = analyze_fold_distribution(stratified_kf, X_imb_scaled, y_imb, \"Stratified K-Fold\")\n",
    "\n",
    "# Calculate variation in class distributions\n",
    "regular_class1_pcts = [dist[1] for dist in regular_dist]\n",
    "stratified_class1_pcts = [dist[1] for dist in stratified_dist]\n",
    "\n",
    "print(f\"\\nüìä Class 1 Distribution Variation:\")\n",
    "print(f\"   Regular K-Fold:    {np.std(regular_class1_pcts):.2f}% std deviation\")\n",
    "print(f\"   Stratified K-Fold: {np.std(stratified_class1_pcts):.2f}% std deviation\")\n",
    "\n",
    "if np.std(regular_class1_pcts) > np.std(stratified_class1_pcts):\n",
    "    print(\"   ‚úÖ Stratified K-Fold has more consistent class distributions!\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è In this case, both methods are similar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Comparison\n",
    "\n",
    "**What we're doing**: Comparing model performance using both CV methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚öñÔ∏è Performance Comparison: Regular vs Stratified CV\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Regular K-Fold CV\n",
    "regular_scores = cross_val_score(\n",
    "    model, X_imb_scaled, y_imb, cv=KFold(n_splits=5, shuffle=True, random_state=42)\n",
    ")\n",
    "\n",
    "# Stratified K-Fold CV\n",
    "stratified_scores = cross_val_score(\n",
    "    model, X_imb_scaled, y_imb, cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    ")\n",
    "\n",
    "print(f\"üìä Results:\")\n",
    "print(f\"Regular K-Fold:\")\n",
    "print(f\"   ‚Ä¢ Scores: {[f'{score:.4f}' for score in regular_scores]}\")\n",
    "print(f\"   ‚Ä¢ Mean: {regular_scores.mean():.4f} ¬± {regular_scores.std():.4f}\")\n",
    "\n",
    "print(f\"\\nStratified K-Fold:\")\n",
    "print(f\"   ‚Ä¢ Scores: {[f'{score:.4f}' for score in stratified_scores]}\")\n",
    "print(f\"   ‚Ä¢ Mean: {stratified_scores.mean():.4f} ¬± {stratified_scores.std():.4f}\")\n",
    "\n",
    "# Visualize the comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plot scores\n",
    "x_pos = np.arange(5)\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x_pos - width/2, regular_scores, width, label='Regular K-Fold', alpha=0.8)\n",
    "plt.bar(x_pos + width/2, stratified_scores, width, label='Stratified K-Fold', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Cross-Validation Scores: Regular vs Stratified K-Fold')\n",
    "plt.xticks(x_pos, [f'Fold {i+1}' for i in range(5)])\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add mean lines\n",
    "plt.axhline(y=regular_scores.mean(), color='blue', linestyle='--', alpha=0.7)\n",
    "plt.axhline(y=stratified_scores.mean(), color='orange', linestyle='--', alpha=0.7)\n\nplt.tight_layout()\nplt.show()\n\nprint(f\"\\nüîç Analysis:\")\nif stratified_scores.std() < regular_scores.std():\n    print(\"   ‚úÖ Stratified CV shows more consistent results!\")\nelse:\n    print(\"   ‚ö†Ô∏è Both methods show similar consistency in this case.\")\n\nprint(f\"\\nüí° Key Takeaway: Always use Stratified K-Fold for classification!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Checkpoint Question 3\n",
    "\n",
    "**Your turn!** Why is Stratified K-Fold better for imbalanced datasets?\n",
    "\n",
    "<details>\n",
    "<summary>Click for explanation</summary>\n",
    "\n",
    "**Answer**: Stratified K-Fold is better because:\n",
    "1. **Preserves class distribution**: Each fold has the same proportion of classes as the original dataset\n",
    "2. **Reduces variance**: More consistent performance estimates across folds\n",
    "3. **Prevents bias**: Avoids folds with very few (or no) minority class samples\n",
    "4. **Better representation**: Each fold is a better representative sample of the overall data\n",
    "\n",
    "This is especially important when classes are imbalanced!\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìñ Part 4: Choosing the Right Number of Folds\n",
    "\n",
    "**The question**: How many folds should you use?\n",
    "\n",
    "**Common choices**:\n",
    "- **5-fold**: Good balance of bias and variance, computationally efficient\n",
    "- **10-fold**: Lower bias, higher variance, more computation\n",
    "- **Leave-One-Out (LOO)**: Lowest bias, highest variance, very expensive\n",
    "\n",
    "**Trade-offs**:\n",
    "- **More folds**: Lower bias (closer to true performance), higher variance, more computation\n",
    "- **Fewer folds**: Higher bias, lower variance, less computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî¨ Experiment: Comparing Different Numbers of Folds\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "fold_options = [3, 5, 10, 20]\n",
    "results = {}\n",
    "\n",
    "for k in fold_options:\n",
    "    print(f\"\\nüìä {k}-Fold Cross-Validation:\")\n",
    "    \n",
    "    # Perform k-fold CV\n",
    "    scores = cross_val_score(model, X_scaled, y, cv=k, scoring='accuracy')\n",
    "    \n",
    "    results[k] = {\n",
    "        'scores': scores,\n",
    "        'mean': scores.mean(),\n",
    "        'std': scores.std(),\n",
    "        'training_size_per_fold': len(X_scaled) * (k-1) / k\n",
    "    }\n",
    "    \n",
    "    print(f\"   ‚Ä¢ Mean accuracy: {scores.mean():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Std deviation: {scores.std():.4f}\")\n",
    "    print(f\"   ‚Ä¢ Training size per fold: {results[k]['training_size_per_fold']:.0f} samples\")\n",
    "\n",
    "# Visualize the comparison\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Mean accuracy and error bars\n",
    "plt.subplot(2, 2, 1)\n",
    "means = [results[k]['mean'] for k in fold_options]\n",
    "stds = [results[k]['std'] for k in fold_options]\n",
    "\n",
    "plt.errorbar(fold_options, means, yerr=stds, marker='o', capsize=5, capthick=2, linewidth=2)\n",
    "plt.xlabel('Number of Folds')\n",
    "plt.ylabel('Mean Accuracy')\n",
    "plt.title('Mean Accuracy vs Number of Folds')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Standard deviation\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(fold_options, stds, 'ro-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Folds')\n",
    "plt.ylabel('Standard Deviation')\n",
    "plt.title('Variance vs Number of Folds')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Training set size\n",
    "plt.subplot(2, 2, 3)\n",
    "training_sizes = [results[k]['training_size_per_fold'] for k in fold_options]\n",
    "plt.plot(fold_options, training_sizes, 'go-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Folds')\n",
    "plt.ylabel('Training Samples per Fold')\n",
    "plt.title('Training Set Size vs Number of Folds')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: All scores distribution\n",
    "plt.subplot(2, 2, 4)\n",
    "for i, k in enumerate(fold_options):\n",
    "    scores = results[k]['scores']\n",
    "    plt.scatter([k] * len(scores), scores, alpha=0.7, s=50, label=f'{k}-fold')\n",
    "\n",
    "plt.xlabel('Number of Folds')\n",
    "plt.ylabel('Individual Fold Scores')\n",
    "plt.title('Score Distribution by Number of Folds')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Summary:\")\n",
    "for k in fold_options:\n",
    "    print(f\"   {k}-fold: {results[k]['mean']:.4f} ¬± {results[k]['std']:.4f}\")\n",
    "\n",
    "print(f\"\\nüí° Recommendations:\")\n",
    "print(f\"   ‚Ä¢ For most cases: Use 5-fold or 10-fold CV\")\n",
    "print(f\"   ‚Ä¢ Small datasets: Use 10-fold or Leave-One-Out\")\n",
    "print(f\"   ‚Ä¢ Large datasets: 3-fold or 5-fold may be sufficient\")\n",
    "print(f\"   ‚Ä¢ Always consider computational cost vs. accuracy trade-off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Final Exercise: Put It All Together\n",
    "\n",
    "**Your challenge**: Complete the following cross-validation analysis!\n",
    "\n",
    "**Task**: Compare two different models using proper cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Final Challenge: Model Comparison with Cross-Validation\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# TODO: Complete this analysis\n",
    "# 1. Create two models: LogisticRegression and RandomForestClassifier\n",
    "model1 = LogisticRegression(random_state=42, max_iter=1000)\n",
    "model2 = ___  # TODO: Create a RandomForestClassifier\n",
    "\n",
    "# 2. Use 5-fold stratified cross-validation for both models\n",
    "cv_strategy = ___  # TODO: Create StratifiedKFold with 5 splits\n",
    "\n",
    "# 3. Get cross-validation scores for both models\n",
    "scores1 = cross_val_score(model1, X_scaled, y, cv=cv_strategy, scoring='accuracy')\n",
    "scores2 = ___  # TODO: Get scores for model2\n",
    "\n",
    "# 4. Compare the results\n",
    "print(f\"Logistic Regression:\")\n",
    "print(f\"   ‚Ä¢ Scores: {[f'{score:.4f}' for score in scores1]}\")\n",
    "print(f\"   ‚Ä¢ Mean: {scores1.mean():.4f} ¬± {scores1.std():.4f}\")\n",
    "\n",
    "print(f\"\\nRandom Forest:\")\n",
    "print(f\"   ‚Ä¢ Scores: {[f'{score:.4f}' for score in scores2]}\")\n",
    "print(f\"   ‚Ä¢ Mean: {scores2.mean():.4f} ¬± {scores2.std():.4f}\")\n",
    "\n",
    "# 5. Statistical comparison\n",
    "from scipy import stats\n",
    "t_stat, p_value = stats.ttest_rel(scores1, scores2)\n",
    "\n",
    "print(f\"\\nüìä Statistical Comparison:\")\n",
    "print(f\"   ‚Ä¢ Difference in means: {scores2.mean() - scores1.mean():.4f}\")\n",
    "print(f\"   ‚Ä¢ T-statistic: {t_stat:.4f}\")\n",
    "print(f\"   ‚Ä¢ P-value: {p_value:.4f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    if scores2.mean() > scores1.mean():\n",
    "        print(f\"   ‚úÖ Random Forest is significantly better!\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Logistic Regression is significantly better!\")\n",
    "else:\n",
    "    print(f\"   ‚öñÔ∏è No significant difference between models.\")\n",
    "\n",
    "# 6. Visualize the comparison\n",
    "plt.figure(figsize=(10, 6))\n",
    "x_pos = np.arange(5)\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x_pos - width/2, scores1, width, label='Logistic Regression', alpha=0.8)\n",
    "plt.bar(x_pos + width/2, scores2, width, label='Random Forest', alpha=0.8)\n",
    "\n",
    "plt.xlabel('Fold Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Comparison: Cross-Validation Scores')\n",
    "plt.xticks(x_pos, [f'Fold {i+1}' for i in range(5)])\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add mean lines\n",
    "plt.axhline(y=scores1.mean(), color='blue', linestyle='--', alpha=0.7)\n",
    "plt.axhline(y=scores2.mean(), color='orange', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>Click for solution</summary>\n",
    "\n",
    "```python\n",
    "# Complete solution:\n",
    "model2 = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores2 = cross_val_score(model2, X_scaled, y, cv=cv_strategy, scoring='accuracy')\n",
    "```\n",
    "\n",
    "**Explanation**: \n",
    "- RandomForestClassifier is an ensemble method that often performs well\n",
    "- StratifiedKFold ensures balanced class distribution in each fold\n",
    "- We use the same CV strategy for fair comparison\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ Congratulations!\n",
    "\n",
    "You've completed the **Basic Cross-Validation** exercise! Here's what you've learned:\n",
    "\n",
    "### ‚úÖ Key Concepts Mastered:\n",
    "1. **Why cross-validation is essential** for reliable model evaluation\n",
    "2. **How to implement k-fold cross-validation** both manually and with scikit-learn\n",
    "3. **The importance of stratified cross-validation** for classification problems\n",
    "4. **How to choose the right number of folds** based on your dataset and constraints\n",
    "5. **How to compare models** using cross-validation results\n",
    "\n",
    "### üöÄ Next Steps:\n",
    "\n",
    "**Ready for more?** Choose your next exercise based on your comfort level:\n",
    "\n",
    "#### Level 2 (Intermediate):\n",
    "- [Complete Model Evaluation Pipeline](./level2_complete_evaluation_pipeline.ipynb)\n",
    "- [Advanced Hyperparameter Optimization](./level2_advanced_hyperparameter_optimization.ipynb)\n",
    "\n",
    "#### Level 3 (Advanced):\n",
    "- [Healthcare Diagnostic Model](./level3_healthcare_diagnostic.ipynb)\n",
    "- [Financial Risk Assessment](./level3_financial_risk_assessment.ipynb)\n",
    "\n",
    "#### Additional Resources:\n",
    "- **[Cross-Validation Guide](../cross-validation.md)**: Deep dive into advanced CV techniques\n",
    "- **[Hyperparameter Tuning Guide](../hyperparameter-tuning.md)**: Learn optimization strategies\n",
    "- **[Main Tutorial](../tutorial.ipynb)**: Comprehensive walkthrough of all concepts\n",
    "\n",
    "### üí° Remember:\n",
    "- **Always use cross-validation** for reliable performance estimates\n",
    "- **Use stratified CV** for classification problems\n",
    "- **Consider computational cost** when choosing number of folds\n",
    "- **Compare models fairly** using the same CV strategy\n",
    "\n",
    "**Great job!** You're well on your way to mastering model evaluation! üåü"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
