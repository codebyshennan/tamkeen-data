# Quiz: Unsupervised Learning

## Questions

1. What is PCA used for?
   _a. Dimensionality reduction_
   b. Classification
   c. Regression
   d. Clustering

**Explanation**: Principal Component Analysis (PCA):
- Reduces data dimensionality
- Preserves maximum variance
- Creates orthogonal components
- Helps visualize high-dimensional data
Key concepts:
- Eigenvalues and eigenvectors
- Explained variance ratio
- Feature correlation
- Linear transformation

*For more information, see: [PCA](../5.4-unsupervised-learning/pca.md)*

2. What is t-SNE best for?
   _a. Visualization of high-dimensional data_
   b. Feature selection
   c. Prediction
   d. Model evaluation

**Explanation**: t-SNE (t-Distributed Stochastic Neighbor Embedding):
- Preserves local structure of data
- Non-linear dimensionality reduction
- Particularly good for visualization
- Maintains clusters and patterns
Important parameters:
- Perplexity
- Learning rate
- Number of iterations
- Early exaggeration

*For more information, see: [TSNE-UMAP](../5.4-unsupervised-learning/tsne-umap.md)*

3. What is k-means clustering?
   _a. Partitioning data into k groups_
   b. Reducing dimensions to k
   c. Selecting k features
   d. Training k models

**Explanation**: K-means clustering:
- Divides data into k clusters
- Minimizes within-cluster variance
- Iterative algorithm
- Centroid-based method
Algorithm steps:
- Initialize centroids
- Assign points to nearest centroid
- Update centroid positions
- Repeat until convergence

*For more information, see: [Clustering](../5.4-unsupervised-learning/clustering.md)*

4. What is hierarchical clustering?
   _a. Creating tree of nested clusters_
   b. Selecting hierarchy of features
   c. Training models in hierarchy
   d. Organizing data in trees

**Explanation**: Hierarchical clustering:
- Builds tree-like cluster hierarchy
- Can be agglomerative or divisive
- Provides multiple clustering levels
- No need to specify clusters upfront
Key concepts:
- Dendrogram visualization
- Linkage methods
- Distance metrics
- Cluster cutting height

*For more information, see: [Advanced Clustering](../5.4-unsupervised-learning/advanced-clustering.md)*

5. What is DBSCAN?
   _a. Density-based clustering_
   b. Distance-based clustering
   c. Distribution-based clustering
   d. Dimension-based clustering

**Explanation**: DBSCAN (Density-Based Spatial Clustering of Applications with Noise):
- Finds clusters based on density
- Handles noise points
- Can find arbitrary-shaped clusters
- No need to specify number of clusters
Key parameters:
- Epsilon (neighborhood distance)
- MinPoints (minimum points for core point)
- Handles varying density
- Identifies outliers naturally

*For more information, see: [Clustering](../5.4-unsupervised-learning/clustering.md)*
